{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a9a49454",
      "metadata": {
        "id": "a9a49454"
      },
      "source": [
        "# Exercise 1 on Clustering: Toy Datasets\n",
        "\n",
        "First, we perform clustering on a simple dataset to illustrate how clustering works.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52cff70d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "52cff70d",
        "outputId": "f9e2201c-4aad-4a8e-f681-a9166310b944"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import datasets\n",
        "\n",
        "n_samples = 500\n",
        "random_state = 170\n",
        "\n",
        "# create dataset\n",
        "dataset = datasets.make_blobs(n_samples=n_samples, cluster_std=[1.0, 1.0, 1.0], random_state=random_state)\n",
        "X = dataset[0] # data\n",
        "y = dataset[1] # labels\n",
        "\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3cf684c",
      "metadata": {
        "id": "c3cf684c"
      },
      "source": [
        "## K-Means\n",
        "\n",
        "K-Means clusters the points based on their Euclidean distance $d_{i,j} = ||\\mathbf{x}_i -  \\mathbf{x}_j||^2_2$. The goal is to minimize the distance between points in the same cluster, and maximize the distance between points from different clusters.\n",
        "\n",
        "The objective function is\n",
        "\\begin{equation}\n",
        "    \\sum_{i=0}^n \\min(||\\mathbf{x}_i - \\boldsymbol{\\mu}_j||^2_2) \\ \\ \\ j = 1, \\dots, n_c\n",
        "\\end{equation}\n",
        "\n",
        "which is also called the inertia.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d775930",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "6d775930",
        "outputId": "595d39b7-7ca5-40a8-c7ec-f340c02b6f8a"
      },
      "outputs": [],
      "source": [
        "# To do:\n",
        "# - center the dataset\n",
        "# - apply KMeans https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans\n",
        "# - plot the data with the centroids and the labels found by KMeans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5d2100d",
      "metadata": {
        "id": "b5d2100d"
      },
      "source": [
        "# Clustering to do LPCA\n",
        "\n",
        "The goal of the exercise is to do clustering on a dataset representing a noisy 2D non-linear function.\n",
        "* How do we select the correct number of clusters?\n",
        "* Why LPCA works better than PCA on a non-linear dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ae6e6c9",
      "metadata": {
        "id": "3ae6e6c9"
      },
      "source": [
        "First thing, we create our synthetic dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9c58ab3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "f9c58ab3",
        "outputId": "ed36849d-a8a0-4c66-f258-cc290eb6e0df",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "def non_linear_func_orig(x):\n",
        "    y = np.sin(x) + np.sin(1.5*x)\n",
        "    return y\n",
        "\n",
        "def non_linear_func(x):\n",
        "    y = np.sin(x) + np.sin(1.5*x) + 0.25*np.random.randn(x.size)\n",
        "    return y\n",
        "\n",
        "# This code is used to create our synthetic dataset\n",
        "size = 1000\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "\n",
        "x = np.random.rand(size) * 2.6*np.pi - np.pi/2\n",
        "y = non_linear_func(x)\n",
        "\n",
        "limits = [np.pi/2.5, 1.2*np.pi]\n",
        "eps = np.pi/10\n",
        "\n",
        "mask = ((x < limits[0] + eps) & (x > limits[0] - eps)) | (x < limits[1] + eps) & (x > limits[1] - eps)\n",
        "x = x[~mask]\n",
        "y = y[~mask]\n",
        "\n",
        "X = np.zeros((x.size, 2))\n",
        "X[:,0] = x\n",
        "X[:,1] = y\n",
        "\n",
        "x_orig = np.linspace(x.min(), x.max(), 200)\n",
        "y_orig = non_linear_func_orig(x_orig)\n",
        "\n",
        "# We can plot the dataset and the original non-linear function\n",
        "plt.scatter(X[:,0], X[:,1], c='b', alpha=0.5)\n",
        "plt.plot(x_orig, y_orig, c='cyan', lw=5)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f427673",
      "metadata": {
        "id": "6f427673"
      },
      "source": [
        "## Global PCA\n",
        "Now we apply the PCA and try to reconstruct the dataset using only one dimension.\n",
        " - To do:\n",
        "    - obtain X_std (dataset preprocessed with mean and STD)\n",
        "    - apply PCA\n",
        "    - recontruct the solution with one dimension (q=1)\n",
        "        -hint:\n",
        "            - X     = Z  @ A.T\n",
        "            - X_rec = Zq @ Aq.T\n",
        "    - plot the reconstruction vs the original dataset\n",
        "\n",
        "\n",
        " - hint: the documentation and examples to use the PCA object are at:\n",
        "       https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bec782f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "8bec782f",
        "outputId": "611de6b7-a125-4150-a2e9-e8d7cd03de9e"
      },
      "outputs": [],
      "source": [
        "# To do:\n",
        "# - Apply PCA\n",
        "# - Reconstruct with a single PC"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "706f512f",
      "metadata": {
        "id": "706f512f"
      },
      "source": [
        "## Clustering\n",
        "\n",
        "We can try and improve the reconstruction accuracy using a local approach. The first thing to do is then to cluster the dataset using kmeans.\n",
        "- To do:\n",
        "    - Use KMeans object to obtain the cluster labels or indexes (=`idx`). init = 'random' and n_init='auto'\n",
        "    - Use a number of clusters (k) of your choice.\n",
        "    - Plot the dataset and colour it by the value of the label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b62e3728",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "b62e3728",
        "outputId": "8e27144b-d1b8-49d6-8bbf-1b3b59c963ce"
      },
      "outputs": [],
      "source": [
        "# To do:\n",
        "# - Apply KMeans to the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b38b55eb",
      "metadata": {
        "id": "b38b55eb"
      },
      "source": [
        "## Selection of the clusters' number\n",
        "\n",
        "In this case we can visually identify the number of clusters, because we have only two dimensions. In higher dimensions, it is not possible to visualize the dataset. Also, we would prefer to have an automatic method to select the correct number of clusters.\n",
        "\n",
        "We can use the Davies-Boulding score to estimate the number of clusters (https://scikit-learn.org/stable/modules/clustering.html#davies-bouldin-index)\n",
        "\n",
        "- To do:\n",
        "    - Calculate the DB score for a range of k (number of clusters) that goes from 2 to 10.\n",
        "    - Plot the DB score as a function of k.\n",
        "    - Select n_clusters based on the DB score\n",
        "   \n",
        "   \n",
        "- Hint:\n",
        "    - the documentation and examples to use the PCA object are at:\n",
        "    https://scikit-learn.org/stable/modules/generated/sklearn.metrics.davies_bouldin_score.html\n",
        "    - you can use a 'for' loop to calculate the DB for different k\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3155a211",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "3155a211",
        "outputId": "27d10db8-b754-4255-cdfb-1e5ae7769305"
      },
      "outputs": [],
      "source": [
        "# To do:\n",
        "# Compute and plot the DB index for n_cluster = 2 to 10"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0c016f3",
      "metadata": {
        "id": "b0c016f3"
      },
      "source": [
        "## Local PCA\n",
        "\n",
        "Now we can apply the PCA in each cluster.\n",
        "- To do:\n",
        "    - apply PCA for each cluster\n",
        "    - plot the reconstruction using only the first PC.\n",
        "- Hint:\n",
        "    - Use a 'for' loop to apply the PCA in each cluster.\n",
        "    - to select only the data of a single cluster use a mask:\n",
        "           To select the data with label 0:\n",
        "             mask = (idx == 0)\n",
        "             X_k = X[mask]\n",
        "    - To get the correct reconstruction, you need to **center and scale** the data **in each cluster** before applying the PCA, and then de-center and de-scale the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1b996cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "e1b996cc",
        "outputId": "766bee08-218c-47b3-ec62-a96616e4bbb6"
      },
      "outputs": [],
      "source": [
        "# To do:\n",
        "# - Apply PCA to each cluster"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dc4b887",
      "metadata": {
        "id": "1dc4b887"
      },
      "source": [
        "## Local PCA with VQPCA\n",
        "\n",
        "We can compare the KMEANS results with VQPCA. To perform VQPCA, we need the [OpenMORe](https://github.com/burn-research/OpenMORe) library. You can run the next cell to install it.\n",
        "VQPCA is a clustering algorithm that assign points to the clusters based on the reconstruction error, so it tries to find clusters that can be well represented by a linear manifold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c162f0c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c162f0c7",
        "outputId": "885759c7-68a4-443e-922f-f6d261089426"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/burn-research/OpenMORe.git\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0,'/content/OpenMORe')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60e30738",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60e30738",
        "outputId": "077f7dc8-4921-4386-fb45-76537c7c43ca"
      },
      "outputs": [],
      "source": [
        "import OpenMORe.clustering as clustering\n",
        "\n",
        "\n",
        "# This is a dictionary used to set the VQPCA parameters.\n",
        "settings_clustering = {\n",
        "    #centering and scaling options\n",
        "    \"center\"                    : True,\n",
        "    \"centering_method\"          : \"mean\",\n",
        "    \"scale\"                     : True,\n",
        "    \"scaling_method\"            : \"auto\",\n",
        "\n",
        "    #set the initialization method (random, observations, kmeans, pkcia, uniform)\n",
        "    \"initialization_method\"     : \"uniform\",\n",
        "\n",
        "    #set the number of clusters and PCs in each cluster\n",
        "    \"number_of_clusters\"        : 3,\n",
        "    \"number_of_eigenvectors\"    : 1,\n",
        "\n",
        "    #enable additional options:\n",
        "    \"correction_factor\"         : \"off\",    # --> enable eventual corrective coefficients for the LPCA algorithm:\n",
        "                                            #     'off', 'c_range', 'uncorrelation', 'local_variance', 'phc_multi', 'local_skewness' are available\n",
        "\n",
        "    \"classify\"                  : False,    # --> call the method to classify a new matrix Y on the basis of the lpca clustering\n",
        "    \"write_on_txt\"              : False,    # --> write the idx vector containing the label for each observation\n",
        "    \"evaluate_clustering\"       : True,     # --> enable the calculation of indeces to evaluate the goodness of the clustering\n",
        "    \"neighbors_number\"          : 0,\n",
        "\n",
        "    \"kNN_post\"                  : False,     # activate the kNN algorithm once the convergence is achieved\n",
        "}\n",
        "\n",
        "# To do: follow the example in\n",
        "# https://github.com/burn-research/OpenMORe/blob/master/examples/clustering/lpcaExample.py\n",
        "# to find the vqpca labels, then plot the clusters\n",
        "\n",
        "# First we create the model and then we fit it to the dataset\n",
        "model = clustering.lpca(X, settings_clustering)\n",
        "idx_vqpca = model.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gmHAkchMc8QA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "gmHAkchMc8QA",
        "outputId": "61693168-419f-4404-bbe1-cf1eaa5f926f"
      },
      "outputs": [],
      "source": [
        "# To do:\n",
        "# - Apply PCA to each cluster"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env_ml2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
