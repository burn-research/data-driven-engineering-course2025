{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a9a49454",
      "metadata": {
        "id": "a9a49454"
      },
      "source": [
        "# Exercise 1 on Clustering: Toy Datasets\n",
        "\n",
        "First, we perform clustering on a simple dataset to illustrate how clustering works.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52cff70d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "52cff70d",
        "outputId": "f9e2201c-4aad-4a8e-f681-a9166310b944"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import datasets\n",
        "\n",
        "n_samples = 500\n",
        "random_state = 170\n",
        "\n",
        "# create dataset\n",
        "dataset = datasets.make_blobs(n_samples=n_samples, cluster_std=[1.0, 1.0, 1.0], random_state=random_state)\n",
        "X = dataset[0] # data\n",
        "y = dataset[1] # labels\n",
        "\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3cf684c",
      "metadata": {
        "id": "c3cf684c"
      },
      "source": [
        "## K-Means\n",
        "\n",
        "K-Means clusters the points based on their Euclidean distance $d_{i,j} = ||\\mathbf{x}_i -  \\mathbf{x}_j||^2_2$. The goal is to minimize the distance between points in the same cluster, and maximize the distance between points from different clusters.\n",
        "\n",
        "The objective function is\n",
        "\\begin{equation}\n",
        "    \\sum_{i=0}^n \\min(||\\mathbf{x}_i - \\boldsymbol{\\mu}_j||^2_2) \\ \\ \\ j = 1, \\dots, n_c\n",
        "\\end{equation}\n",
        "\n",
        "which is also called the inertia.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d775930",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "6d775930",
        "outputId": "595d39b7-7ca5-40a8-c7ec-f340c02b6f8a"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "X0 = StandardScaler().fit_transform(X)\n",
        "kmeans = KMeans(n_clusters=3, random_state=0, n_init=\"auto\").fit(X0)\n",
        "\n",
        "centroids = kmeans.cluster_centers_\n",
        "labels = kmeans.labels_\n",
        "\n",
        "plt.scatter(X0[:, 0], X0[:, 1], c=labels)\n",
        "plt.scatter(centroids[:, 0], centroids[:, 1], c='r', label='centroids')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5d2100d",
      "metadata": {
        "id": "b5d2100d"
      },
      "source": [
        "# Clustering to do LPCA\n",
        "\n",
        "The goal of the exercise is to do clustering on a dataset representing a noisy 2D non-linear function.\n",
        "* How do we select the correct number of clusters?\n",
        "* Why LPCA works better than PCA on a non-linear dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ae6e6c9",
      "metadata": {
        "id": "3ae6e6c9"
      },
      "source": [
        "First thing, we create our synthetic dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9c58ab3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "f9c58ab3",
        "outputId": "ed36849d-a8a0-4c66-f258-cc290eb6e0df",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "\n",
        "def non_linear_func_orig(x):\n",
        "    y = np.sin(x) + np.sin(1.5*x)\n",
        "    return y\n",
        "\n",
        "def non_linear_func(x):\n",
        "    y = np.sin(x) + np.sin(1.5*x) + 0.25*np.random.randn(x.size)\n",
        "    return y\n",
        "\n",
        "# This code is used to create our synthetic dataset\n",
        "size = 1000\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "\n",
        "x = np.random.rand(size) * 2.6*np.pi - np.pi/2\n",
        "y = non_linear_func(x)\n",
        "\n",
        "limits = [np.pi/2.5, 1.2*np.pi]\n",
        "eps = np.pi/10\n",
        "\n",
        "mask = ((x < limits[0] + eps) & (x > limits[0] - eps)) | (x < limits[1] + eps) & (x > limits[1] - eps)\n",
        "x = x[~mask]\n",
        "y = y[~mask]\n",
        "\n",
        "X = np.zeros((x.size, 2))\n",
        "X[:,0] = x\n",
        "X[:,1] = y\n",
        "\n",
        "x_orig = np.linspace(x.min(), x.max(), 200)\n",
        "y_orig = non_linear_func_orig(x_orig)\n",
        "\n",
        "# We can plot the dataset and the original non-linear function\n",
        "plt.scatter(X[:,0], X[:,1], c='b', alpha=0.5)\n",
        "plt.plot(x_orig, y_orig, c='cyan', lw=5)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f427673",
      "metadata": {
        "id": "6f427673"
      },
      "source": [
        "## Global PCA\n",
        "Now we apply the PCA and try to reconstruct the dataset using only one dimension.\n",
        " - To do:\n",
        "    - obtain X_std (dataset preprocessed with mean and STD)\n",
        "    - apply PCA\n",
        "    - recontruct the solution with one dimension (q=1)\n",
        "        -hint:\n",
        "            - X     = Z  @ A.T\n",
        "            - X_rec = Zq @ Aq.T\n",
        "    - plot the reconstruction vs the original dataset\n",
        "\n",
        "\n",
        " - hint: the documentation and examples to use the PCA object are at:\n",
        "       https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bec782f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "8bec782f",
        "outputId": "611de6b7-a125-4150-a2e9-e8d7cd03de9e"
      },
      "outputs": [],
      "source": [
        "# We import the PCA object from the sklearn package\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X0 = scaler.fit_transform(X)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA()\n",
        "pca.fit(X0)\n",
        "\n",
        "A = pca.components_.T\n",
        "Z = X0 @ A\n",
        "\n",
        "# Reconstruct with 1 PC\n",
        "q=1\n",
        "X0_rec = Z[:,:q] @ A[:,:q].T\n",
        "X_rec = scaler.inverse_transform(X0_rec)\n",
        "\n",
        "# plot the reconstruction VS original\n",
        "\n",
        "plt.scatter(X[:,0], X[:,1], c='b', alpha=0.5)\n",
        "plt.plot(x_orig, y_orig, c='cyan', lw=5)\n",
        "plt.scatter(X_rec[:,0], X_rec[:,1], c='red', alpha=0.5)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "706f512f",
      "metadata": {
        "id": "706f512f"
      },
      "source": [
        "## Clustering\n",
        "\n",
        "We can try and improve the reconstruction accuracy using a local approach. The first thing to do is then to cluster the dataset using kmeans.\n",
        "- To do:\n",
        "    - Use KMeans object to obtain the cluster labels or indexes (=`idx`). init = 'random' and n_init='auto'\n",
        "    - Use a number of clusters (k) of your choice.\n",
        "    - Plot the dataset and colour it by the value of the label\n",
        "   \n",
        "   \n",
        "- Hint: the documentation and examples to use the PCA object are at:\n",
        "       https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b62e3728",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "b62e3728",
        "outputId": "8e27144b-d1b8-49d6-8bbf-1b3b59c963ce"
      },
      "outputs": [],
      "source": [
        "# We import the KMEANS object from the sklearn package\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Number of clusters\n",
        "k=4\n",
        "\n",
        "# Perform KMeans\n",
        "kmeans = KMeans(n_clusters=k, init='random', n_init='auto')\n",
        "kmeans.fit(X0)\n",
        "idx = kmeans.labels_\n",
        "\n",
        "# Plot the clustering\n",
        "# Uncomment the lines below when you have calculated the clusters' labels (=idx).\n",
        "plt.scatter(X0[:,0], X0[:,1], c=idx)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b38b55eb",
      "metadata": {
        "id": "b38b55eb"
      },
      "source": [
        "## Selection of the clusters' number\n",
        "\n",
        "In this case we can visually identify the number of clusters, because we have only two dimensions. In higher dimensions, it is not possible to visualize the dataset. Also, we would prefer to have an automatic method to select the correct number of clusters.\n",
        "\n",
        "We can use the Davies Bouldin score to estimate the number of clusters.\n",
        "\n",
        "- To do:\n",
        "    - Calculate the DB score for a range of k (number of clusters) that goes from 2 to 10.\n",
        "    - Plot the DB score as a function of k.\n",
        "    - Select n_clusters based on the DB score\n",
        "   \n",
        "   \n",
        "- Hint:\n",
        "    - the documentation and examples to use the PCA object are at:\n",
        "    https://scikit-learn.org/stable/modules/generated/sklearn.metrics.davies_bouldin_score.html\n",
        "    - you can use a 'for' loop to calculate the DB for different k\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3155a211",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "3155a211",
        "outputId": "27d10db8-b754-4255-cdfb-1e5ae7769305"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import davies_bouldin_score\n",
        "\n",
        "# Create the k_array and the db_score_array, initiliazed with zeros\n",
        "k_array         = np.arange(2,10)\n",
        "db_score_array  = np.zeros((k_array.size,))\n",
        "\n",
        "# Loop on k where: 1) perform KMeans, 2) calculate db_score and 3) stores them in db_score_array\n",
        "for i,k in enumerate(k_array):\n",
        "    kmeans = KMeans(n_clusters=k, init='random', n_init='auto')\n",
        "    kmeans.fit(X0)\n",
        "    idx = kmeans.labels_\n",
        "\n",
        "    db_score = davies_bouldin_score(X, idx)\n",
        "    db_score_array[i] = db_score\n",
        "\n",
        "# Plot DB score Vs n_clusters\n",
        "plt.plot(k_array, db_score_array)\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('db_score')\n",
        "plt.show()\n",
        "\n",
        "# Select n_clusters based on db_scores\n",
        "index = np.argmin(db_score_array)\n",
        "n_clusters = k_array[index]\n",
        "\n",
        "print(f'n_clusters = {n_clusters}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0c016f3",
      "metadata": {
        "id": "b0c016f3"
      },
      "source": [
        "## Local PCA\n",
        "\n",
        "Now we can apply the PCA in each cluster.\n",
        "- To do:\n",
        "    - apply PCA for each cluster\n",
        "    - plot the reconstruction using only the first PC.\n",
        "- Hint:\n",
        "    - Use a 'for' loop to apply the PCA in each cluster.\n",
        "    - to select only the data of a single cluster use a mask:\n",
        "           To select the data with label 0:\n",
        "             mask = (idx == 0)\n",
        "             X_k = X[mask]\n",
        "    - To get the correct reconstruction, you need to **center and scale** the data **in each cluster** before applying the PCA, and then de-center and de-scale the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1b996cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "e1b996cc",
        "outputId": "766bee08-218c-47b3-ec62-a96616e4bbb6"
      },
      "outputs": [],
      "source": [
        "# We compute Kmeans with the correct number of clusters\n",
        "kmeans = KMeans(n_clusters=n_clusters, init='random', n_init='auto')\n",
        "kmeans.fit(X0)\n",
        "idx = kmeans.labels_\n",
        "\n",
        "q = 1\n",
        "\n",
        "# We create the PCA object\n",
        "pca = PCA()\n",
        "\n",
        "# Loop on clusters:\n",
        "for k in range(n_clusters):\n",
        "    print(f' k = {k}')\n",
        "\n",
        "    # create the mask: select the points belonging to cluster k\n",
        "    mask = (idx==k)\n",
        "    X_k  = X[mask]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X0_k = scaler.fit_transform(X_k)\n",
        "\n",
        "    # perform the pca\n",
        "    pca.fit(X0_k)\n",
        "    A_k = pca.components_.T\n",
        "    Z_k = X0_k @ A_k\n",
        "\n",
        "    # recontruct and uncenter and unscale\n",
        "    X0_k_rec = Z_k[:,:q] @ A_k[:,:q].T\n",
        "    X_k_rec = scaler.inverse_transform(X0_k_rec)\n",
        "\n",
        "    # plot the reconstruction\n",
        "    plt.scatter(X_k[:,0]    ,X_k[:,1],     c='b', alpha=0.5)\n",
        "    plt.scatter(X_k_rec[:,0],X_k_rec[:,1], c='r', alpha=0.5)\n",
        "\n",
        "plt.plot(x_orig, y_orig, c='cyan', lw=5, alpha=0.7)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dc4b887",
      "metadata": {
        "id": "1dc4b887"
      },
      "source": [
        "## Local PCA with VQPCA\n",
        "\n",
        "We can compare the KMEANS results with VQPCA. To perform VQPCA, we need the [OpenMORe](https://github.com/burn-research/OpenMORe) library. You can run the next cell to install it.\n",
        "VQPCA is a clustering algorithm that assign points to the clusters based on the reconstruction error, so it tries to find clusters that can be well represented by a linear manifold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c162f0c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c162f0c7",
        "outputId": "885759c7-68a4-443e-922f-f6d261089426"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/burn-research/OpenMORe.git\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0,'/content/OpenMORe')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60e30738",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60e30738",
        "outputId": "077f7dc8-4921-4386-fb45-76537c7c43ca"
      },
      "outputs": [],
      "source": [
        "import OpenMORe.clustering as clustering\n",
        "\n",
        "# This is a dictionary used to set the VQPCA parameters.\n",
        "settings_clustering = {\n",
        "    #centering and scaling options\n",
        "    \"center\"                    : True,\n",
        "    \"centering_method\"          : \"mean\",\n",
        "    \"scale\"                     : True,\n",
        "    \"scaling_method\"            : \"auto\",\n",
        "\n",
        "    #set the initialization method (random, observations, kmeans, pkcia, uniform)\n",
        "    \"initialization_method\"     : \"uniform\",\n",
        "\n",
        "    #set the number of clusters and PCs in each cluster\n",
        "    \"number_of_clusters\"        : 3,\n",
        "    \"number_of_eigenvectors\"    : 1,\n",
        "\n",
        "    #enable additional options:\n",
        "    \"correction_factor\"         : \"off\",    # --> enable eventual corrective coefficients for the LPCA algorithm:\n",
        "                                            #     'off', 'c_range', 'uncorrelation', 'local_variance', 'phc_multi', 'local_skewness' are available\n",
        "\n",
        "    \"classify\"                  : False,    # --> call the method to classify a new matrix Y on the basis of the lpca clustering\n",
        "    \"write_on_txt\"              : False,    # --> write the idx vector containing the label for each observation\n",
        "    \"evaluate_clustering\"       : True,     # --> enable the calculation of indeces to evaluate the goodness of the clustering\n",
        "    \"neighbors_number\"          : 0,\n",
        "\n",
        "    \"kNN_post\"                  : False,     # activate the kNN algorithm once the convergence is achieved\n",
        "}\n",
        "\n",
        "# To do: follow the example in\n",
        "# https://github.com/burn-research/OpenMORe/blob/master/examples/clustering/lpcaExample.py\n",
        "# to find the vqpca labels, then plot the clusters\n",
        "\n",
        "# First we create the model and then we fit it to the dataset\n",
        "model = clustering.lpca(X, settings_clustering)\n",
        "idx_vqpca = model.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b0cc159",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "9b0cc159",
        "outputId": "b4a49ee5-d7ff-43ee-9eee-be6dbba0ac07"
      },
      "outputs": [],
      "source": [
        "# Now we can plot the clusters\n",
        "plt.scatter(X[:,0], X[:,1], c=idx_vqpca)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gmHAkchMc8QA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "gmHAkchMc8QA",
        "outputId": "61693168-419f-4404-bbe1-cf1eaa5f926f"
      },
      "outputs": [],
      "source": [
        "# We create the PCA object\n",
        "pca = PCA()\n",
        "\n",
        "# Loop on clusters:\n",
        "for k in range(n_clusters):\n",
        "    print(f' k = {k}')\n",
        "\n",
        "    # create the mask: select the points belonging to cluster k\n",
        "    mask = (idx_vqpca==k)\n",
        "    X_k  = X[mask]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X0_k = scaler.fit_transform(X_k)\n",
        "\n",
        "    # perform the pca\n",
        "    pca.fit(X0_k)\n",
        "    A_k = pca.components_.T\n",
        "    Z_k = X0_k @ A_k\n",
        "\n",
        "    # recontruct and uncenter and unscale\n",
        "    X0_k_rec = Z_k[:,:q] @ A_k[:,:q].T\n",
        "    X_k_rec = scaler.inverse_transform(X0_k_rec)\n",
        "\n",
        "    # plot the reconstruction\n",
        "    plt.scatter(X_k[:,0]    ,X_k[:,1],     c='b', alpha=0.5)\n",
        "    plt.scatter(X_k_rec[:,0],X_k_rec[:,1], c='r', alpha=0.5)\n",
        "\n",
        "plt.plot(x_orig, y_orig, c='cyan', lw=5, alpha=0.7)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env_ml2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
